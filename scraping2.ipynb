{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "714153fc-fae1-4be8-bcf5-5e702f921789",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 117)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<string>:117\u001b[1;36m\u001b[0m\n\u001b[1;33m    max_pages = 30  # Adjust as needed\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article\n",
    "import pandas as pd\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    " # List of Indian health news URLs\n",
    "news_sources = {\n",
    "    \"The Hindu\": \"https://www.thehindu.com/sci-tech/health/\",\n",
    "    \"Indian Express\": \"https://indianexpress.com/section/lifestyle/health/\",\n",
    "    \"Times of India\": \"https://timesofindia.indiatimes.com/life-style/health-fitness/health-news\",\n",
    "    \"The Wire\": \"https://thewire.in/health\",\n",
    "    \"Scroll\": \"https://scroll.in/topic/451/health\",\n",
    "    \"Swarajya\": \"https://swarajyamag.com/health\",\n",
    "    \"OpIndia\": \"https://www.opindia.com/category/health/\",\n",
    "    \"The Quint\": \"https://www.thequint.com/news/health\",\n",
    "    \"NDTV Health\": \"https://www.ndtv.com/health\",\n",
    "    \"News18\": \"https://www.news18.com/health/\",\n",
    "    \"ABP Live\": \"https://news.abplive.com/health\",\n",
    "    \"Deccan Herald\": \"https://www.deccanherald.com/specials/health/\",\n",
    "    \"Business Standard\": \"https://www.business-standard.com/category/health\",\n",
    "    \"Hindustan Times\": \"https://www.hindustantimes.com/health\",\n",
    "    \"Livemint\": \"https://www.livemint.com/health\",\n",
    "    \"Economic Times Health\": \"https://economictimes.indiatimes.com/industry/healthcare/biotech\",\n",
    "    \"India Today Health\": \"https://www.indiatoday.in/health\",\n",
    "    \"DNA India\": \"https://www.dnaindia.com/health\",\n",
    "    \"Firstpost\": \"https://www.firstpost.com/health\",\n",
    "    \"Asian Age\": \"https://www.asianage.com/health\",\n",
    "    \"Outlook India\": \"https://www.outlookindia.com/topic/health\",\n",
    "    \"Zee News Health\": \"https://zeenews.india.com/health\",\n",
    "    \"One India Health\": \"https://www.oneindia.com/health\",\n",
    "    \"Rediff Health\": \"https://www.rediff.com/getahead/health.html\",\n",
    "    \"Mid-Day\": \"https://www.mid-day.com/lifestyle/health\",\n",
    "    \"The Pioneer\": \"https://www.dailypioneer.com/health\",\n",
    "    \"Greater Kashmir\": \"https://www.greaterkashmir.com/health\",\n",
    "    \"Tribune India\": \"https://www.tribuneindia.com/section/health\",\n",
    "    \"ET Health World\": \"https://health.economictimes.indiatimes.com\",\n",
    "    \"Medical Dialogues\": \"https://medicaldialogues.in\",\n",
    "    \"Pharmabiz\": \"http://www.pharmabiz.com/\",\n",
    "    \"The Statesman Health\": \"https://www.thestatesman.com/health\",\n",
    "    \"The Print\": \"https://theprint.in/health\",\n",
    "    \"The Sentinel Assam\": \"https://www.sentinelassam.com/health\",\n",
    "    \"The Shillong Times\": \"https://theshillongtimes.com/health\",\n",
    "    \"North East Today\": \"https://www.northeasttoday.in/health\",\n",
    "    \"Morung Express\": \"https://morungexpress.com/health\",\n",
    "    \"Assam Tribune\": \"https://www.assamtribune.com/health\",\n",
    "    \"Nagaland Post\": \"https://nagalandpost.com/category/health\",\n",
    "    \"The Citizen\": \"https://www.thecitizen.in/topic/health\",\n",
    "    \"IndiaSpend\": \"https://www.indiaspend.com/health\",\n",
    "    \"Healthworld\": \"https://health.economictimes.indiatimes.com\",\n",
    "    \"People Matters\": \"https://www.peoplematters.in/topic/health\",\n",
    "    \"Business Today Health\": \"https://www.businesstoday.in/latest/trends/health\",\n",
    "    \"Indian Health Journal\": \"https://indianhealthjournal.com/\",\n",
    "    \"Express Healthcare\": \"https://www.expresshealthcare.in/\",\n",
    "    \"India Science Wire\": \"https://indiasciencewire.org/health\",\n",
    "    \"Research Matters\": \"https://researchmatters.in/section/health\",\n",
    "    \"Down to Earth\": \"https://www.downtoearth.org.in/category/health\",\n",
    "    \"The Better India Health\": \"https://www.thebetterindia.com/topics/health/\",\n",
    "    \"Youth Ki Awaaz\": \"https://www.youthkiawaaz.com/category/health/\",\n",
    "    \"The Logical Indian\": \"https://thelogicalindian.com/health\"\n",
    "}\n",
    " # Fast Chrome user-agent\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "}\n",
    " # Thread-safe storage\n",
    "lock = threading.Lock()\n",
    "all_articles = []\n",
    " def fetch_article(url, source):\n",
    "   \"\"\"Fetch article using either Newspaper or BS4.\"\"\"\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        if len(article.text.split()) > 200:\n",
    "            return {\n",
    "                \"source\": source,\n",
    "                \"title\": article.title,\n",
    "                \"text\": article.text,\n",
    "                \"url\": url\n",
    "            }\n",
    "    except Exception:\n",
    "        try:\n",
    "            res = requests.get(url, headers=headers, timeout=10)\n",
    "            soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "            title_tag = soup.find(\"title\")\n",
    "            title = title_tag.text.strip() if title_tag else \"\"\n",
    "            paragraphs = soup.find_all('p')\n",
    "\n",
    "            text = \" \".join(p.get_text(strip=True) for p in paragraphs)\n",
    "\n",
    "            if len(text.split()) > 200:\n",
    "\n",
    "                return {\n",
    "\n",
    "                    \"source\": source,\n",
    "\n",
    "                    \"title\": title,\n",
    "\n",
    "                    \"text\": text,\n",
    "\n",
    "                    \"url\": url\n",
    "\n",
    "                }\n",
    "\n",
    "        except:\n",
    "\n",
    "            return None\n",
    " \n",
    "def scrape_source(source, base_url):\n",
    "\n",
    "    \"\"\"Scrape all articles from a single source.\"\"\"\n",
    "    urls_collected = set()\n",
    "   max_pages = 30  # Adjust as needed\n",
    "     # Parallelize pagination\n",
    "    def collect_links(page):\n",
    "        page_url = f\"{base_url}?page={page}\"\n",
    "        try:\n",
    "            response = requests.get(page_url, headers=headers, timeout=10)\n",
    "            if response.status_code != 200:\n",
    "                return []\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            links = soup.find_all('a', href=True)\n",
    "            return [\n",
    "                urljoin(base_url, link['href'])\n",
    "                for link in links\n",
    "                if \"health\" in link['href'] and not link['href'].endswith(('.jpg', '.png', '.pdf'))\n",
    "            ]\n",
    "        except:\n",
    "           return []\n",
    "     with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(collect_links, page) for page in range(1, max_pages + 1)]\n",
    "        for future in as_completed(futures):\n",
    "            urls_collected.update(future.result())\n",
    " \n",
    "    # Parallelize article extraction\n",
    "    with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "        futures = [executor.submit(fetch_article, url, source) for url in urls_collected]\n",
    "        for future in as_completed(futures):\n",
    "            article = future.result()\n",
    "            if article:\n",
    "                with lock:\n",
    "                    all_articles.append(article)\n",
    "                if len(all_articles) >= 10000:  # Stop if target is reached\n",
    "                    return\n",
    " \n",
    "# Scrape all sources\n",
    "for source, base_url in tqdm(news_sources.items(), desc=\"News Sources\"):\n",
    "    scrape_source(source, base_url)\n",
    " \n",
    "# Save to CSV\n",
    "df = pd.DataFrame(all_articles)\n",
    "df.drop_duplicates(subset=\"url\", inplace=True)\n",
    "df.to_csv(\"indian_health_bias_new2.csv\", index=False)\n",
    "print(f\"\\nâœ… Saved {len(df)} articles to 'indian_health_bias_news_optimized.csv'\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc24e52-09a6-49a8-8100-c0204b7bcf1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
